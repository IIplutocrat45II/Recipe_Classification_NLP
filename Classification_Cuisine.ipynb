{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://cpb-us-e1.wpmucdn.com/blogs.ntu.edu.sg/dist/c/1998/files/2019/06/NTU_Logo_Colour_RGB_Positive.png\" alt=\"logo\" style=\"width: 400px;\" align=\"left\"/>\n",
    "<img src=\"https://www.pinclipart.com/picdir/big/178-1781047_clip-arts-related-to-google-kaggle-png-download.png\" style=\"width: 400px;\" align=\"center\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> <u>EE0005: Introduction to Data Science and Artifical Intelligence - Mini Project</u></h1>\n",
    "<h2>What's Cooking? </h2>\n",
    "\n",
    "We have used a kaggle dataset called \"What's cooking\" (Ref: https://www.kaggle.com/c/whats-cooking/data) to do the following: \n",
    "1. Data exploration and visualization.\n",
    "2. create a deep learning model **to classify a given receipe into different cuisines**. \n",
    "\n",
    "\n",
    "<font size=\"3.5\">\n",
    "    <br><b><u>Made by:</u></b>\n",
    "    <br>Siddesh Sambasivam Suseela\n",
    "    <br>Jain Shlok\n",
    "</font>\n",
    "\n",
    "-----\n",
    "\n",
    "<font size=\"4\"><b><u>Pre-requisites:</u></b></font>\n",
    "<br><br><b><u>Libraries:</u></b>\n",
    "<br><font size=\"2.5\">**Data Handling:** Numpy, Pandas </font>\n",
    "<br><font size=\"2.5\">**Data Visulization:** seaborn, matplotlib </font>\n",
    "<br><font size=\"2.5\">**Deep learning framework:** Tensorflow </font>\n",
    "<br><font size=\"2.5\">**Misc:** sklearn </font>\n",
    "\n",
    "<br><font size=\"2.5\"><b><u>Dataset:</u></b> <a href=\"https://www.kaggle.com/c/whats-cooking/data\">https://www.kaggle.com/c/whats-cooking/data</a> </font>\n",
    "\n",
    "-----\n",
    "\n",
    "<h3>Objective: Classify a given receipe to its respective cuisine </h3>\n",
    "<br><u>Example:</u>\n",
    "<br><center>receipe --> Cuisine</center>\n",
    "<br><center>'romaine lettuce black olives grape tomatoes garlic pepper purple onion seasoning garbanzo beans feta cheese crumbles' --> greek </center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Importing the dependencies</h2>\n",
    "\n",
    "---\n",
    "\n",
    "<img src=\"Images/pd.png\" style=\"width: 400px;\" align='left'>\n",
    "<img src=\"Images/skl.png\" style=\"width: 200px;\" align='left'>\n",
    "<img src=\"Images/tf.png\" style=\"width: 300px;\" align='left'>\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prodigy/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/prodigy/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/prodigy/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/prodigy/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/prodigy/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/prodigy/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/prodigy/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/prodigy/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/prodigy/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/prodigy/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/prodigy/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/prodigy/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from sklearn.model_selection import KFold\n",
    "sb.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Installing the dependencies</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Ver:\n",
      "\n",
      "2.0.0-alpha0\n"
     ]
    }
   ],
   "source": [
    "# Checking the version of the tensorflow, as we will be using tensorflow2.0 for this project\n",
    "\n",
    "print(\"Tensorflow Ver:\\n\")\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached https://files.pythonhosted.org/packages/d3/59/d88fe8c58ffb66aca21d03c0e290cd68327cc133591130c674985e98a482/tensorflow-1.14.0-cp27-cp27mu-manylinux1_x86_64.whl\n",
      "Collecting grpcio>=1.8.6 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/69/46/ebd21ce467ab87f2cf825413273936f9b1ee0e6cd4e2f2ee62e0516c771f/grpcio-1.25.0-cp27-cp27mu-manylinux1_x86_64.whl\n",
      "Collecting mock>=2.0.0 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/05/d2/f94e68be6b17f46d2c353564da56e6fb89ef09faeeff3313a046cb810ca9/mock-3.0.5-py2.py3-none-any.whl\n",
      "Collecting keras-applications>=1.0.6 (from tensorflow)\n",
      "Collecting wrapt>=1.11.1 (from tensorflow)\n",
      "Collecting protobuf>=3.6.1 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/c5/49/ffa7ab9c52ec56b535cffec3bc844254c073888e6d4aeee464671ac97480/protobuf-3.10.0-cp27-cp27mu-manylinux1_x86_64.whl\n",
      "Collecting keras-preprocessing>=1.0.5 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl\n",
      "Collecting gast>=0.2.0 (from tensorflow)\n",
      "Collecting wheel (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/00/83/b4a77d044e78ad1a45610eb88f745be2fd2c6d658f9798a15e384b7d57c9/wheel-0.33.6-py2.py3-none-any.whl\n",
      "Collecting enum34>=1.1.6 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/c5/db/e56e6b4bbac7c4a06de1c50de6fe1ef3810018ae11732a50f15f62c7d050/enum34-1.1.6-py2-none-any.whl\n",
      "Collecting numpy<2.0,>=1.14.5 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/d7/b1/3367ea1f372957f97a6752ec725b87886e12af1415216feec9067e31df70/numpy-1.16.5-cp27-cp27mu-manylinux1_x86_64.whl\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "Collecting six>=1.10.0 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/65/26/32b8464df2a97e6dd1b656ed26b2c194606c16fe163c695a992b36c11cdf/six-1.13.0-py2.py3-none-any.whl\n",
      "Collecting absl-py>=0.7.0 (from tensorflow)\n",
      "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl\n",
      "Collecting tensorboard<1.15.0,>=1.14.0 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/f4/37/e6a7af1c92c5b68fb427f853b06164b56ea92126bcfd87784334ec5e4d42/tensorboard-1.14.0-py2-none-any.whl\n",
      "Collecting google-pasta>=0.1.6 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/2d/68/eed71ec8e8383a43987e0a58492b0aa043dc29971cac59b8b1d1e7951123/google_pasta-0.1.8-py2-none-any.whl\n",
      "Collecting backports.weakref>=1.0rc1 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/88/ec/f598b633c3d5ffe267aaada57d961c94fdfa183c5c3ebda2b6d151943db6/backports.weakref-1.0.post1-py2.py3-none-any.whl\n",
      "Collecting astor>=0.6.0 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/d1/4f/950dfae467b384fc96bc6469de25d832534f6b4441033c39f914efd13418/astor-0.8.0-py2.py3-none-any.whl\n",
      "Collecting futures>=2.2.0; python_version < \"3.2\" (from grpcio>=1.8.6->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/69/cb/f5be453359271714c01b9bd06126eaf2e368f1fddfff30818754b5ac2328/funcsigs-1.0.2-py2.py3-none-any.whl\n",
      "Collecting h5py (from keras-applications>=1.0.6->tensorflow)\n",
      "^C\n",
      "Collecting numpy\n",
      "  Using cached https://files.pythonhosted.org/packages/d7/b1/3367ea1f372957f97a6752ec725b87886e12af1415216feec9067e31df70/numpy-1.16.5-cp27-cp27mu-manylinux1_x86_64.whl\n",
      "Installing collected packages: numpy\n",
      "Successfully installed numpy-1.16.5\n",
      "Collecting sklearn\n",
      "Collecting scikit-learn (from sklearn)\n",
      "  Using cached https://files.pythonhosted.org/packages/31/9f/042db462417451e81035c3d43b722e88450c628a33dfda69777a801b0d40/scikit_learn-0.20.4-cp27-cp27mu-manylinux1_x86_64.whl\n",
      "Collecting scipy>=0.13.3 (from scikit-learn->sklearn)\n",
      "  Using cached https://files.pythonhosted.org/packages/1d/f6/7c16d60aeb3694e5611976cb4f1eaf1c6b7f1e7c55771d691013405a02ea/scipy-1.2.2-cp27-cp27mu-manylinux1_x86_64.whl\n",
      "Collecting numpy>=1.8.2 (from scikit-learn->sklearn)\n",
      "  Using cached https://files.pythonhosted.org/packages/d7/b1/3367ea1f372957f97a6752ec725b87886e12af1415216feec9067e31df70/numpy-1.16.5-cp27-cp27mu-manylinux1_x86_64.whl\n",
      "Installing collected packages: numpy, scipy, scikit-learn, sklearn\n",
      "^C\n",
      "\u001b[31mOperation cancelled by user\u001b[0m\n",
      "Collecting tqdm\n",
      "  Using cached https://files.pythonhosted.org/packages/05/f2/764a5d530cf143ded9bc95216edb6e258c6554511e78de7c250557e8f3ed/tqdm-4.37.0-py2.py3-none-any.whl\n",
      "Installing collected packages: tqdm\n",
      "Successfully installed tqdm-4.37.0\n",
      "Collecting seaborn\n",
      "Collecting pandas>=0.15.2 (from seaborn)\n",
      "  Using cached https://files.pythonhosted.org/packages/db/83/7d4008ffc2988066ff37f6a0bb6d7b60822367dcb36ba5e39aa7801fda54/pandas-0.24.2-cp27-cp27mu-manylinux1_x86_64.whl\n",
      "Collecting scipy>=0.14.0 (from seaborn)\n",
      "  Using cached https://files.pythonhosted.org/packages/1d/f6/7c16d60aeb3694e5611976cb4f1eaf1c6b7f1e7c55771d691013405a02ea/scipy-1.2.2-cp27-cp27mu-manylinux1_x86_64.whl\n",
      "Collecting matplotlib>=1.4.3 (from seaborn)\n",
      "  Using cached https://files.pythonhosted.org/packages/32/6b/0368cfa5e1d1ae169ab7dc78addda3fd5e6262e48d7373a9114bac7caff7/matplotlib-2.2.4-cp27-cp27mu-manylinux1_x86_64.whl\n",
      "Collecting numpy>=1.9.3 (from seaborn)\n",
      "  Using cached https://files.pythonhosted.org/packages/d7/b1/3367ea1f372957f97a6752ec725b87886e12af1415216feec9067e31df70/numpy-1.16.5-cp27-cp27mu-manylinux1_x86_64.whl\n",
      "Collecting pytz>=2011k (from pandas>=0.15.2->seaborn)\n",
      "  Using cached https://files.pythonhosted.org/packages/e7/f9/f0b53f88060247251bf481fa6ea62cd0d25bf1b11a87888e53ce5b7c8ad2/pytz-2019.3-py2.py3-none-any.whl\n",
      "Collecting python-dateutil>=2.5.0 (from pandas>=0.15.2->seaborn)\n",
      "  Using cached https://files.pythonhosted.org/packages/d4/70/d60450c3dd48ef87586924207ae8907090de0b306af2bce5d134d78615cb/python_dateutil-2.8.1-py2.py3-none-any.whl\n",
      "Collecting cycler>=0.10 (from matplotlib>=1.4.3->seaborn)\n",
      "  Using cached https://files.pythonhosted.org/packages/f7/d2/e07d3ebb2bd7af696440ce7e754c59dd546ffe1bbe732c8ab68b9c834e61/cycler-0.10.0-py2.py3-none-any.whl\n",
      "Collecting backports.functools-lru-cache (from matplotlib>=1.4.3->seaborn)\n",
      "  Using cached https://files.pythonhosted.org/packages/da/d1/080d2bb13773803648281a49e3918f65b31b7beebf009887a529357fd44a/backports.functools_lru_cache-1.6.1-py2.py3-none-any.whl\n",
      "Collecting subprocess32 (from matplotlib>=1.4.3->seaborn)\n",
      "Collecting kiwisolver>=1.0.1 (from matplotlib>=1.4.3->seaborn)\n",
      "  Using cached https://files.pythonhosted.org/packages/3d/78/cb9248b2289ec31e301137cedbe4ca503a74ca87f88cdbfd2f8be52323bf/kiwisolver-1.1.0-cp27-cp27mu-manylinux1_x86_64.whl\n",
      "Collecting six>=1.10 (from matplotlib>=1.4.3->seaborn)\n",
      "  Using cached https://files.pythonhosted.org/packages/65/26/32b8464df2a97e6dd1b656ed26b2c194606c16fe163c695a992b36c11cdf/six-1.13.0-py2.py3-none-any.whl\n",
      "Collecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 (from matplotlib>=1.4.3->seaborn)\n",
      "  Using cached https://files.pythonhosted.org/packages/a3/c4/7828cf9e71ce8fbd43c1e502f3fdd0498f069fcf9d1c268205ce278ae201/pyparsing-2.4.4-py2.py3-none-any.whl\n",
      "Collecting setuptools (from kiwisolver>=1.0.1->matplotlib>=1.4.3->seaborn)\n",
      "  Using cached https://files.pythonhosted.org/packages/d9/de/554b6310ac87c5b921bc45634b07b11394fe63bc4cb5176f5240addf18ab/setuptools-41.6.0-py2.py3-none-any.whl\n",
      "Installing collected packages: numpy, pytz, six, python-dateutil, pandas, scipy, cycler, backports.functools-lru-cache, subprocess32, setuptools, kiwisolver, pyparsing, matplotlib, seaborn\n"
     ]
    }
   ],
   "source": [
    "# If the above version is not 2.0, then run the following cell\n",
    "!pip install --upgrade tensorflow\n",
    "\n",
    "#Installing other dependencies\n",
    "!pip install numpy\n",
    "!pip install sklearn\n",
    "!pip install tqdm\n",
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tensorflow version: \",tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Loading the dataset from the JSON file</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the training and test data\n",
    "\n",
    "with open(\"Data/train.json\") as f:\n",
    "    raw_train_data = json.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datatype(TRAIN):  <class 'list'>\n",
      "Size of the training data=  (39774, 3)\n",
      "\n",
      "Number of records 39774\n"
     ]
    }
   ],
   "source": [
    "#Converting the json file to dataframe\n",
    "\n",
    "print(\"Datatype(TRAIN): \", type(raw_train_data))\n",
    "raw_data_train_df = pd.DataFrame(raw_train_data)\n",
    "print(\"Size of the training data= \", raw_data_train_df.shape)\n",
    "\n",
    "print(\"\\nNumber of records {}\".format(len(raw_data_train_df.id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cuisine</th>\n",
       "      <th>ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>10259</td>\n",
       "      <td>greek</td>\n",
       "      <td>[romaine lettuce, black olives, grape tomatoes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>25693</td>\n",
       "      <td>southern_us</td>\n",
       "      <td>[plain flour, ground pepper, salt, tomatoes, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>20130</td>\n",
       "      <td>filipino</td>\n",
       "      <td>[eggs, pepper, salt, mayonaise, cooking oil, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>22213</td>\n",
       "      <td>indian</td>\n",
       "      <td>[water, vegetable oil, wheat, salt]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>13162</td>\n",
       "      <td>indian</td>\n",
       "      <td>[black pepper, shallots, cornflour, cayenne pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6602</td>\n",
       "      <td>jamaican</td>\n",
       "      <td>[plain flour, sugar, butter, eggs, fresh ginge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>42779</td>\n",
       "      <td>spanish</td>\n",
       "      <td>[olive oil, salt, medium shrimp, pepper, garli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3735</td>\n",
       "      <td>italian</td>\n",
       "      <td>[sugar, pistachio nuts, white almond bark, flo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>16903</td>\n",
       "      <td>mexican</td>\n",
       "      <td>[olive oil, purple onion, fresh pineapple, por...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>12734</td>\n",
       "      <td>italian</td>\n",
       "      <td>[chopped tomatoes, fresh basil, garlic, extra-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id      cuisine                                        ingredients\n",
       "0  10259        greek  [romaine lettuce, black olives, grape tomatoes...\n",
       "1  25693  southern_us  [plain flour, ground pepper, salt, tomatoes, g...\n",
       "2  20130     filipino  [eggs, pepper, salt, mayonaise, cooking oil, g...\n",
       "3  22213       indian                [water, vegetable oil, wheat, salt]\n",
       "4  13162       indian  [black pepper, shallots, cornflour, cayenne pe...\n",
       "5   6602     jamaican  [plain flour, sugar, butter, eggs, fresh ginge...\n",
       "6  42779      spanish  [olive oil, salt, medium shrimp, pepper, garli...\n",
       "7   3735      italian  [sugar, pistachio nuts, white almond bark, flo...\n",
       "8  16903      mexican  [olive oil, purple onion, fresh pineapple, por...\n",
       "9  12734      italian  [chopped tomatoes, fresh basil, garlic, extra-..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data_train_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Description of the dataset</h2>\n",
    "\n",
    "---\n",
    "<b>Columns:</b> \n",
    "<br>     Id \n",
    "<br> Cuisine \n",
    "<br>Ingredients \n",
    "\n",
    "Example of a node in the **train.json**:\n",
    "<br>\n",
    "{\n",
    "  <br> <b>\"id\":</b> 24717,\n",
    "  <br> <b>\"cuisine\":</b> \"indian\",\n",
    "  <br> <b>\"ingredients\":</b> [\n",
    "     \"tumeric\",\n",
    "     \"vegetable stock\",\n",
    "     \"tomatoes\",\n",
    "     \"garam masala\",\n",
    "     \"naan\",\n",
    "     \"red lentils\",\n",
    "     \"red chili peppers\",\n",
    "     \"onions\",\n",
    "     \"spinach\",\n",
    "     \"sweet potatoes\"\n",
    " ]\n",
    " <br>}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Data exploration and visualization</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 39774 entries, 0 to 39773\n",
      "Data columns (total 3 columns):\n",
      "id             39774 non-null int64\n",
      "cuisine        39774 non-null object\n",
      "ingredients    39774 non-null object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 932.3+ KB\n"
     ]
    }
   ],
   "source": [
    "#List of all the cuisines\n",
    "cuisine = list(raw_data_train_df['cuisine'].unique())\n",
    "\n",
    "#Indexing the cuisines for reference\n",
    "index_label = dict()\n",
    "\n",
    "for i,val in enumerate(cuisine):\n",
    "    index_label.update({val:i})\n",
    "\n",
    "raw_data_train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class labels with average number of samples:\n",
      "-------------\n",
      "\n",
      "italian         0.197063\n",
      "mexican         0.161865\n",
      "southern_us     0.108614\n",
      "indian          0.075502\n",
      "chinese         0.067205\n",
      "french          0.066526\n",
      "cajun_creole    0.038870\n",
      "thai            0.038694\n",
      "japanese        0.035777\n",
      "greek           0.029542\n",
      "spanish         0.024865\n",
      "korean          0.020868\n",
      "vietnamese      0.020742\n",
      "moroccan        0.020642\n",
      "british         0.020214\n",
      "filipino        0.018982\n",
      "irish           0.016770\n",
      "jamaican        0.013225\n",
      "russian         0.012294\n",
      "brazilian       0.011741\n",
      "Name: cuisine, dtype: float64\n",
      "\n",
      "Number of classes=  20\n",
      "\n",
      "Number of unique ingredients 6714\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nClass labels with average number of samples:\\n-------------\\n\")\n",
    "#Prints the count of values in each cuisine\n",
    "print(raw_data_train_df.cuisine.value_counts(normalize=True))\n",
    "\n",
    "#Basic exploration\n",
    "print(\"\\nNumber of classes= \", len(raw_data_train_df['cuisine'].unique()))\n",
    "print(\"\\nNumber of unique ingredients {}\\n\".format(len(set([ingredient for ingredient_list in raw_data_train_df.ingredients.values for ingredient in ingredient_list]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average size of the receipe in each cuisine:\n",
      "\n",
      "greek=  10.1821\n",
      "southern_us=  9.635\n",
      "filipino=  10.0\n",
      "indian=  12.706\n",
      "jamaican=  12.2148\n",
      "spanish=  10.4237\n",
      "italian=  9.909\n",
      "mexican=  10.8774\n",
      "chinese=  11.9828\n",
      "british=  9.709\n",
      "thai=  12.5458\n",
      "vietnamese=  12.6752\n",
      "cajun_creole=  12.6171\n",
      "brazilian=  9.5203\n",
      "french=  9.8178\n",
      "japanese=  9.7351\n",
      "irish=  9.2999\n",
      "korean=  11.2843\n",
      "moroccan=  12.9099\n",
      "russian=  10.2249\n"
     ]
    }
   ],
   "source": [
    "class_average = [0]*20\n",
    "cus_vis = dict()\n",
    "print(\"\\nAverage size of the receipe in each cuisine:\\n\")\n",
    "for cus in cuisine:\n",
    "    avg_size = 0\n",
    "    tmp = raw_data_train_df[raw_data_train_df['cuisine']==cus]\n",
    "    for val in tmp['ingredients']:\n",
    "        avg_size+=len(val)\n",
    "    class_average[index_label[cus]]= avg_size/len(tmp)\n",
    "    print(f\"{cus}= \", round(class_average[index_label[cus]],4))\n",
    "    cus_vis.update({cus:avg_size/len(tmp)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fa9f0b97ef0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the count plot to visulize the distribution of data\n",
    "sb.countplot(y='cuisine',data=raw_data_train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Data preparation: </h2> \n",
    "<br>Cleaning the data and normalizing all the text by converting it to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_prepare(ingredient):\n",
    "    \n",
    "    #Compilation of all the special characters\n",
    "    REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "    \n",
    "    #Replacing the character\n",
    "    ingredient = re.sub(REPLACE_BY_SPACE_RE,' ',ingredient)\n",
    "    \n",
    "    #Converting the text to lowercase\n",
    "    ingredient = ingredient.lower()\n",
    "    \n",
    "    ingredient = ingredient.strip()\n",
    "    ingredient = ' '.join([word for word in ingredient.split(\" \")])\n",
    "    \n",
    "    return ingredient\n",
    "    print(\"\\nClass labels with average number of samples:\\n-------------\\n\")\n",
    "\n",
    "def loader(ingredient_list):    \n",
    "    return ' '.join([text_prepare(ingredient) for ingredient in ingredient_list])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_train_df[\"ingredients\"] = raw_data_train_df['ingredients'].apply(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plain flour ground pepper salt tomatoes ground black pepper thyme eggs green tomatoes yellow corn meal milk vegetable oil\n",
      "\n",
      " southern_us\n"
     ]
    }
   ],
   "source": [
    "print(raw_data_train_df[\"ingredients\"][1])\n",
    "print(\"\\n\", raw_data_train_df[\"cuisine\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values(['brazilian', 'british', 'cajun_creole', 'chinese', 'filipino', 'french', 'greek', 'indian', 'irish', 'italian', 'jamaican', 'japanese', 'korean', 'mexican', 'moroccan', 'russian', 'southern_us', 'spanish', 'thai', 'vietnamese'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ref: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html\n",
    "\n",
    "#Encoding the cuisine\n",
    "LabelEncd = LabelEncoder()\n",
    "LabelEncd.fit(raw_data_train_df['cuisine'].values)\n",
    "\n",
    "vec2tag = dict()\n",
    "for i,labels in enumerate(list(LabelEncd.classes_)):\n",
    "    vec2tag.update({i:labels})\n",
    "vec2tag.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels dimension=  (39774, 20)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ingrd = raw_data_train_df['ingredients'].values\n",
    "\n",
    "labels_enc = LabelEncd.transform(raw_data_train_df[\"cuisine\"].values)\n",
    "labels = to_categorical(labels_enc)\n",
    "print(\"Labels dimension= \", labels.shape)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size=  3065\n"
     ]
    }
   ],
   "source": [
    "#We are using the keras's Tokenizer to tokenize all the words \n",
    "#in the ingredients column.\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_ingrd)\n",
    "vocabularySize = len(tokenizer.word_index) + 1\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "encoded_train_text = tokenizer.texts_to_sequences(train_ingrd)\n",
    "\n",
    "print(\"Vocabulary Size= \",vocabularySize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39774\n"
     ]
    }
   ],
   "source": [
    "# We pad the vectors to normalize the length of the sentence.\n",
    "max_length = 40\n",
    "padded_train_docs = pad_sequences(encoded_train_text, maxlen=max_length, padding='post')\n",
    "print(len(padded_train_docs))\n",
    "\n",
    "#Creating a dictionary for lookup after prediction\n",
    "reverse_word_index = dict([(value,key) for (key, value) in word_index.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<h3>GloVe: Global Vectors for Word Representation</h3>\n",
    "<p>GloVe is an unsupervised learning algorithm for obtaining vector representations for words. Training is performed on aggregated global word-word co-occurrence statistics from a corpus, and the resulting representations showcase interesting linear substructures of the word vector space.<p>\n",
    "\n",
    "For further reference: <a href=\"https://nlp.stanford.edu/projects/glove/\">https://nlp.stanford.edu/projects/glove/</a>\n",
    "\n",
    "**Usage:**\n",
    "<br>We use glove to represent the words as a vector. The model that we chose is a glove.6B.100d which is trained on 6-Billion words and each word is represented by a 100-dimensional vector.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# Loading the glove model.\n",
    "\n",
    "embeddings_index = dict()\n",
    "f = open('glove_embedding/glove.6B.100d.txt') #glove.6B.100d.txt\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a vocabulary list and writing it into a csv file\n",
    "\n",
    "vocab = pd.DataFrame.from_dict(tokenizer.word_index,orient=\"index\")\n",
    "vocab.drop([0],axis=1).reset_index().rename(columns={\"index\":\"word\"}).to_csv(\"vocab.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:**\n",
    "<br>Create a weight matrix for words in training text where we look up the vector value for the particular word on the **glove embedding**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3065, 100)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "embedding_matrix = np.zeros((vocabularySize, 100))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<h2>Machine Learning and New concepts</h2>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:**\n",
    "This function creates the model by instanciating the layers of the neural network and then we compile the model with the loss function and optimizer.\n",
    "\n",
    "<h3><b><u>Neural network Architecture:</u></b></h3>\n",
    "\n",
    "---\n",
    "<u>Layer 1:</u>\n",
    "```python\n",
    "tf.keras.layers.Embedding \n",
    "```\n",
    "1st layer to get the word embedding as input to the neural network\n",
    "\n",
    "---\n",
    "<u>Layer 2:</u>\n",
    "```python\n",
    "tf.keras.layers.Conv1D\n",
    "```\n",
    "The convolutional layer reduces the size of the inputs by performing convolutional operation on the input data.\n",
    "\n",
    "---\n",
    "<u>Layer 3:</u>\n",
    "```python\n",
    "tf.keras.layers.MaxPooling1D\n",
    "```\n",
    "The MaxPooling reduces the size of the input data from layer 2 to half its original size.\n",
    "\n",
    "---\n",
    "<u>Layer 4:</u>\n",
    "```python\n",
    "tf.keras.layers.Flatten\n",
    "```\n",
    "Flattens the data into a vector\n",
    "\n",
    "---\n",
    "<u>Layer 5:</u>\n",
    "```python\n",
    "tf.keras.layers.Dense\n",
    "```\n",
    "Dense is a fully connected layer with 250 neurons with a activation function of relu. \n",
    "\n",
    "---\n",
    "<u>Layer 6:</u>\n",
    "```python\n",
    "tf.keras.layers.Dense\n",
    "```\n",
    "This is the output layer with number of output neurons equal to the number of classes. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def model():\n",
    "    model = tf.keras.models.Sequential([\n",
    "            Embedding(vocabularySize, 100, weights=[embedding_matrix], \n",
    "                      input_length=40, trainable=False),\n",
    "            Conv1D(filters=100,kernel_size=3, padding='same', \n",
    "                   activation='relu'),\n",
    "            MaxPooling1D(pool_size=2),\n",
    "            Flatten(),\n",
    "            Dense(250, activation='relu'),\n",
    "            Dense(LabelEncd.classes_.size, activation='sigmoid')\n",
    "            ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', \n",
    "                  metrics=['acc'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 40, 100)           306500    \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 40, 100)           30100     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 20, 100)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 250)               500250    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                5020      \n",
      "=================================================================\n",
      "Total params: 841,870\n",
      "Trainable params: 535,370\n",
      "Non-trainable params: 306,500\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>NOTE:</b>\n",
    "\n",
    "Since there is no testing data provided, we validated our model using **K-Fold cross validation method** and averaged the accuracy score.\n",
    "\n",
    "For further reference: <a href=\"https://machinelearningmastery.com/k-fold-cross-validation/\">https://machinelearningmastery.com/k-fold-cross-validation/</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "31819/31819 [==============================] - 9s 271us/sample - loss: 0.1454 - acc: 0.9561\n",
      "Epoch 2/5\n",
      "31819/31819 [==============================] - 7s 217us/sample - loss: 0.1024 - acc: 0.9660\n",
      "Epoch 3/5\n",
      "31819/31819 [==============================] - 7s 231us/sample - loss: 0.0879 - acc: 0.9702\n",
      "Epoch 4/5\n",
      "31819/31819 [==============================] - 8s 243us/sample - loss: 0.0771 - acc: 0.9735\n",
      "Epoch 5/5\n",
      "31819/31819 [==============================] - 7s 231us/sample - loss: 0.0683 - acc: 0.9763\n",
      "7955/7955 [==============================] - 1s 75us/sample - loss: 0.0803 - acc: 0.9724\n",
      "acc: 97.24%\n",
      "------------------------------------------------------------------------------------------------\n",
      "Epoch 1/5\n",
      "31819/31819 [==============================] - 6s 197us/sample - loss: 0.0656 - acc: 0.9774\n",
      "Epoch 2/5\n",
      "31819/31819 [==============================] - 7s 211us/sample - loss: 0.0579 - acc: 0.9799\n",
      "Epoch 3/5\n",
      "31819/31819 [==============================] - 7s 210us/sample - loss: 0.0513 - acc: 0.9823\n",
      "Epoch 4/5\n",
      "31819/31819 [==============================] - 7s 220us/sample - loss: 0.0455 - acc: 0.9843\n",
      "Epoch 5/5\n",
      "31819/31819 [==============================] - 7s 212us/sample - loss: 0.0401 - acc: 0.9863\n",
      "7955/7955 [==============================] - 1s 74us/sample - loss: 0.0686 - acc: 0.9765\n",
      "acc: 97.65%\n",
      "------------------------------------------------------------------------------------------------\n",
      "Epoch 1/5\n",
      "31819/31819 [==============================] - 7s 223us/sample - loss: 0.0451 - acc: 0.9847\n",
      "Epoch 2/5\n",
      "31819/31819 [==============================] - 6s 200us/sample - loss: 0.0381 - acc: 0.9871\n",
      "Epoch 3/5\n",
      "31819/31819 [==============================] - 6s 200us/sample - loss: 0.0331 - acc: 0.9890\n",
      "Epoch 4/5\n",
      "31819/31819 [==============================] - 7s 227us/sample - loss: 0.0286 - acc: 0.9906\n",
      "Epoch 5/5\n",
      "31819/31819 [==============================] - 6s 200us/sample - loss: 0.0243 - acc: 0.9921\n",
      "7955/7955 [==============================] - 1s 72us/sample - loss: 0.0463 - acc: 0.9836\n",
      "acc: 98.36%\n",
      "------------------------------------------------------------------------------------------------\n",
      "Epoch 1/5\n",
      "31819/31819 [==============================] - 7s 211us/sample - loss: 0.0292 - acc: 0.9903\n",
      "Epoch 2/5\n",
      "31819/31819 [==============================] - 7s 227us/sample - loss: 0.0223 - acc: 0.9929\n",
      "Epoch 3/5\n",
      "31819/31819 [==============================] - 6s 200us/sample - loss: 0.0183 - acc: 0.9945\n",
      "Epoch 4/5\n",
      "31819/31819 [==============================] - 7s 232us/sample - loss: 0.0149 - acc: 0.9956\n",
      "Epoch 5/5\n",
      "31819/31819 [==============================] - 7s 208us/sample - loss: 0.0121 - acc: 0.9967\n",
      "7955/7955 [==============================] - 1s 80us/sample - loss: 0.0327 - acc: 0.9883\n",
      "acc: 98.83%\n",
      "------------------------------------------------------------------------------------------------\n",
      "Epoch 1/5\n",
      "31820/31820 [==============================] - 7s 217us/sample - loss: 0.0177 - acc: 0.9943\n",
      "Epoch 2/5\n",
      "31820/31820 [==============================] - 7s 214us/sample - loss: 0.0112 - acc: 0.9969\n",
      "Epoch 3/5\n",
      "31820/31820 [==============================] - 6s 197us/sample - loss: 0.0086 - acc: 0.9978\n",
      "Epoch 4/5\n",
      "31820/31820 [==============================] - 7s 210us/sample - loss: 0.0067 - acc: 0.9985\n",
      "Epoch 5/5\n",
      "31820/31820 [==============================] - 7s 215us/sample - loss: 0.0053 - acc: 0.9990\n",
      "7954/7954 [==============================] - 1s 83us/sample - loss: 0.0188 - acc: 0.9927\n",
      "acc: 99.27%\n",
      "------------------------------------------------------------------------------------------------\n",
      "\n",
      "Accuracy:98.27% (+/- 0.75%)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "kfold = KFold(5, shuffle=True, random_state=42)\n",
    "CrossValidationScores = []\n",
    "\n",
    "for train, test in kfold.split(padded_train_docs, labels):\n",
    "    model.fit(padded_train_docs[train], labels[train],epochs=5)\n",
    "    scores = model.evaluate(padded_train_docs[test], labels[test])\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    print(\"------------------------------------------------------------------------------------------------\")\n",
    "    CrossValidationScores.append(scores[1]*100)\n",
    "print(\"\\nAccuracy:%.2f%% (+/- %.2f%%)\" % (np.mean(CrossValidationScores), \n",
    "                               np.std(CrossValidationScores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<h2>Testing the model with user inputs</h2>\n",
    "\n",
    "---\n",
    "\n",
    "1. Cleaning the given string. \n",
    "```python\n",
    "v = text_prepare(string)\n",
    "```\n",
    "\n",
    "2. Converting the cleaned text ot sequences.\n",
    "```python\n",
    "EnSeq = tokenizer.texts_to_sequences([v])\n",
    "```\n",
    "\n",
    "3. Since our model's input size is of (x, 40) (where x is number of samples), we pad the sequence to length of 40.\n",
    "```python\n",
    "padd_seq = pad_sequences(EnSeq, maxlen=40, padding='post')\n",
    "```\n",
    "\n",
    "4. Using the trained model to predict.\n",
    "```python\n",
    "pred = model.predict(padd_seq)\n",
    "```\n",
    "\n",
    "5. We get the most recurring class among the list of words.\n",
    "\n",
    "```python\n",
    "tpred = [LabelEncd.classes_[np.argmax(prediction)] for prediction in pred]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(string):\n",
    "    cleanedText = text_prepare(string)\n",
    "    EnSeq = tokenizer.texts_to_sequences([cleanedText])\n",
    "    padd_seq = pad_sequences(EnSeq, maxlen=40, padding='post')\n",
    "    print(\"Shape of the padded seuqence= \", padd_seq.shape)\n",
    "    pred = model.predict(padd_seq)\n",
    "    tpred = [LabelEncd.classes_[np.argmax(prediction)] for prediction in pred]\n",
    "    return tpred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\"> **Note:** 'exit' is escape keyword</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the reciepe: masala\n",
      "Shape of the padded seuqence=  (1, 40)\n",
      "['indian']\n",
      "Enter the reciepe: pasta\n",
      "Shape of the padded seuqence=  (1, 40)\n",
      "['italian']\n",
      "Enter the reciepe: black bean\n",
      "Shape of the padded seuqence=  (1, 40)\n",
      "['russian']\n",
      "Enter the reciepe: apple\n",
      "Shape of the padded seuqence=  (1, 40)\n",
      "['mexican']\n"
     ]
    }
   ],
   "source": [
    "string = ''\n",
    "while string!='exit':\n",
    "    string = str(input(\"Enter the reciepe: \"))\n",
    "    if string != 'exit' and string !=\"\" and string!=\" \":\n",
    "        print(pred(string))\n",
    "    else:\n",
    "        pass\n",
    "    if string == \"exit\":\n",
    "        print(\"\\n[0]Exiting...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<h2>Writing out the meta data for further visulaization using tensorflow projector</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3064/3064 [00:00<00:00, 11535.02it/s]\n"
     ]
    }
   ],
   "source": [
    "out_v = io.open('vecs.tsv', 'w', encoding='utf-8')\n",
    "out_m = io.open('meta.tsv', 'w', encoding='utf-8')\n",
    "\n",
    "for word_num in tqdm(range(1, vocabularySize)):\n",
    "  word = reverse_word_index[word_num]\n",
    "  embeddings = embedding_matrix[word_num]\n",
    "  out_m.write(word + \"\\n\")\n",
    "  out_v.write('\\t'.join([str(x) for x in embeddings]) + \"\\n\")\n",
    "    \n",
    "out_v.close()\n",
    "out_m.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<h2>Visualizing the word embeddings</h2>\n",
    "\n",
    "We make use of the tensorflow projector to visualize the words in the 3D space.\n",
    "\n",
    "Reference: <a href=\"https://projector.tensorflow.org/\">https://projector.tensorflow.org/</a>\n",
    "<br>\n",
    "**NOTE:** The Vector TSV file and the Meta TSV File "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/pizza.png\">\n",
    "<br>\n",
    "<img src=\"Images/pasta.png\">\n",
    "<br>\n",
    "<img src=\"Images/naan.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
